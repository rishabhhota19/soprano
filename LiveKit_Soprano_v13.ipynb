{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¤ LiveKit Voice Agent v13\n",
                "\n",
                "**Whisper + Gemini + Soprano - CLEAN VERSION**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q \"livekit-agents[google,silero]~=1.3\" soprano-tts faster-whisper"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ[\"LIVEKIT_URL\"] = \"wss://test-jllkasbg.livekit.cloud\"\n",
                "os.environ[\"LIVEKIT_API_KEY\"] = \"APIFnsAaWh3eFdR\"\n",
                "os.environ[\"LIVEKIT_API_SECRET\"] = \"WabCvkbupgaGfV7JQKBdZNDlYXuRFrr9jZcu7HTFdfG\"\n",
                "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD9sGx9FmvzIl7NtgU7vdwJVgs7NohSSqI\"\n",
                "os.environ[\"HF_HOME\"] = \"/content/hf_cache\"\n",
                "print(\"âœ… Ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile agent_v13.py\n",
                "import asyncio\n",
                "import re\n",
                "import numpy as np\n",
                "from typing import AsyncIterable\n",
                "\n",
                "from livekit import agents, rtc\n",
                "from livekit.agents import Agent, AgentSession, ModelSettings, cli, stt\n",
                "from livekit.plugins import google, silero\n",
                "\n",
                "SOPRANO = None\n",
                "WHISPER = None\n",
                "\n",
                "def load_models():\n",
                "    global SOPRANO, WHISPER\n",
                "    if WHISPER is None:\n",
                "        print(\"Loading Whisper...\")\n",
                "        from faster_whisper import WhisperModel\n",
                "        WHISPER = WhisperModel(\"tiny\", device=\"cuda\", compute_type=\"float16\")\n",
                "        print(\"âœ… Whisper ready\")\n",
                "    if SOPRANO is None:\n",
                "        print(\"Loading Soprano...\")\n",
                "        from soprano import SopranoTTS\n",
                "        SOPRANO = SopranoTTS(device=\"cuda\")\n",
                "        print(\"âœ… Soprano ready\")\n",
                "\n",
                "\n",
                "class VoiceAgent(Agent):\n",
                "    def __init__(self):\n",
                "        super().__init__(instructions=\"You are a helpful voice assistant. Keep responses short.\")\n",
                "        self._sent_re = re.compile(r\"(.+?[.!?]\\s+|.+?\\n+)\", re.DOTALL)\n",
                "\n",
                "    async def stt_node(self, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings):\n",
                "        chunks = []\n",
                "        async for frame in audio:\n",
                "            chunks.append(np.frombuffer(frame.data, dtype=np.int16))\n",
                "        \n",
                "        if not chunks:\n",
                "            yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "            return\n",
                "        \n",
                "        audio_np = np.concatenate(chunks).astype(np.float32) / 32768.0\n",
                "        \n",
                "        try:\n",
                "            segments, _ = WHISPER.transcribe(audio_np, beam_size=1, language=\"en\")\n",
                "            text = \" \".join(s.text for s in segments).strip()\n",
                "            print(f\"ðŸŽ¤ User: {text}\")\n",
                "            if text:\n",
                "                yield stt.SpeechEvent(\n",
                "                    type=stt.SpeechEventType.FINAL_TRANSCRIPT,\n",
                "                    alternatives=[stt.SpeechData(text=text, language=\"en\")],\n",
                "                )\n",
                "        except Exception as e:\n",
                "            print(f\"STT error: {e}\")\n",
                "        \n",
                "        yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "\n",
                "    async def tts_node(self, text: AsyncIterable[str], model_settings: ModelSettings):\n",
                "        buffer = \"\"\n",
                "        sr, spf = 32000, 640\n",
                "\n",
                "        def to_frames(pcm):\n",
                "            pcm = np.clip(pcm, -1.0, 1.0)\n",
                "            pcm_i16 = (pcm * 32767).astype(np.int16)\n",
                "            for i in range(0, len(pcm_i16), spf):\n",
                "                chunk = pcm_i16[i:i+spf]\n",
                "                if len(chunk) < spf:\n",
                "                    chunk = np.pad(chunk, (0, spf - len(chunk)))\n",
                "                yield rtc.AudioFrame(data=chunk.tobytes(), sample_rate=sr, num_channels=1, samples_per_channel=spf)\n",
                "\n",
                "        async def speak(sentence):\n",
                "            sentence = sentence.strip()\n",
                "            if not sentence:\n",
                "                return\n",
                "            print(f\"ðŸ”Š Speaking: {sentence}\")\n",
                "            try:\n",
                "                for chunk in SOPRANO.infer_stream(sentence, chunk_size=1):\n",
                "                    for frame in to_frames(np.asarray(chunk, dtype=np.float32)):\n",
                "                        yield frame\n",
                "            except Exception as e:\n",
                "                print(f\"TTS error: {e}\")\n",
                "\n",
                "        async for delta in text:\n",
                "            buffer += delta\n",
                "            while (m := self._sent_re.match(buffer)):\n",
                "                sentence = m.group(1)\n",
                "                buffer = buffer[len(sentence):]\n",
                "                async for frame in speak(sentence):\n",
                "                    yield frame\n",
                "        if buffer.strip():\n",
                "            async for frame in speak(buffer):\n",
                "                yield frame\n",
                "\n",
                "\n",
                "async def entrypoint(ctx: agents.JobContext):\n",
                "    load_models()\n",
                "    await ctx.connect()\n",
                "    print(f\"âœ… Connected: {ctx.room.name}\")\n",
                "    \n",
                "    vad = silero.VAD.load(min_speech_duration=0.05, min_silence_duration=0.4)\n",
                "    print(\"âœ… VAD ready\")\n",
                "    \n",
                "    session = AgentSession(\n",
                "        turn_detection=\"vad\",\n",
                "        vad=vad,\n",
                "        llm=google.LLM(model=\"gemini-2.0-flash\"),\n",
                "    )\n",
                "    \n",
                "    await session.start(agent=VoiceAgent(), room=ctx.room)\n",
                "    print(\"\\nðŸŽ¤ LISTENING...\\n\")\n",
                "    \n",
                "    done = asyncio.Event()\n",
                "    ctx.room.on(\"disconnected\")(lambda: done.set())\n",
                "    await done.wait()\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    cli.run_app(agents.WorkerOptions(entrypoint_fnc=entrypoint))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python agent_v13.py start"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}