{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé§ LiveKit Voice Agent v10\n",
                "\n",
                "**Self-Hosted Whisper API ‚Üí Gemini Flash ‚Üí Soprano TTS**\n",
                "\n",
                "Architecture:\n",
                "- Cell 1: Start Whisper API server (separate process)\n",
                "- Cell 2: Run Agent (only loads Soprano TTS)\n",
                "\n",
                "This reduces memory usage by keeping models in separate processes!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q \"livekit-agents[google,silero]~=1.3\" soprano-tts faster-whisper fastapi uvicorn httpx"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# LiveKit credentials\n",
                "os.environ[\"LIVEKIT_URL\"] = \"wss://test-jllkasbg.livekit.cloud\"\n",
                "os.environ[\"LIVEKIT_API_KEY\"] = \"APIFnsAaWh3eFdR\"\n",
                "os.environ[\"LIVEKIT_API_SECRET\"] = \"WabCvkbupgaGfV7JQKBdZNDlYXuRFrr9jZcu7HTFdfG\"\n",
                "\n",
                "# Gemini for LLM\n",
                "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD9sGx9FmvzIl7NtgU7vdwJVgs7NohSSqI\"\n",
                "\n",
                "os.environ[\"HF_HOME\"] = \"/content/hf_cache\"\n",
                "\n",
                "print(\"‚úÖ Credentials set\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Create & Start Whisper API Server"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile whisper_server.py\n",
                "\"\"\"Whisper STT API Server - runs on port 8000\"\"\"\n",
                "\n",
                "import io\n",
                "import numpy as np\n",
                "from fastapi import FastAPI, UploadFile, File\n",
                "from fastapi.responses import JSONResponse\n",
                "import uvicorn\n",
                "\n",
                "app = FastAPI()\n",
                "\n",
                "# Load Whisper model at startup\n",
                "WHISPER = None\n",
                "\n",
                "@app.on_event(\"startup\")\n",
                "async def load_model():\n",
                "    global WHISPER\n",
                "    print(\"Loading Faster Whisper...\")\n",
                "    from faster_whisper import WhisperModel\n",
                "    WHISPER = WhisperModel(\"tiny\", device=\"cuda\", compute_type=\"float16\")\n",
                "    print(\"‚úÖ Whisper ready on port 8000\")\n",
                "\n",
                "@app.post(\"/transcribe\")\n",
                "async def transcribe(audio: UploadFile = File(...), sample_rate: int = 16000):\n",
                "    \"\"\"Transcribe audio bytes (int16 PCM) to text\"\"\"\n",
                "    try:\n",
                "        audio_bytes = await audio.read()\n",
                "        # Convert int16 bytes to float32\n",
                "        audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)\n",
                "        audio_float = audio_int16.astype(np.float32) / 32768.0\n",
                "        \n",
                "        # Transcribe\n",
                "        segments, _ = WHISPER.transcribe(audio_float, beam_size=1, language=\"en\")\n",
                "        text = \" \".join(s.text for s in segments).strip()\n",
                "        \n",
                "        return {\"text\": text, \"success\": True}\n",
                "    except Exception as e:\n",
                "        return {\"text\": \"\", \"success\": False, \"error\": str(e)}\n",
                "\n",
                "@app.get(\"/health\")\n",
                "async def health():\n",
                "    return {\"status\": \"ok\", \"model\": \"whisper-tiny\"}\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start Whisper server in background\n",
                "import subprocess\n",
                "import time\n",
                "\n",
                "print(\"üöÄ Starting Whisper API server...\")\n",
                "whisper_process = subprocess.Popen(\n",
                "    [\"python\", \"whisper_server.py\"],\n",
                "    stdout=subprocess.PIPE,\n",
                "    stderr=subprocess.STDOUT\n",
                ")\n",
                "\n",
                "# Wait for server to start\n",
                "time.sleep(10)\n",
                "\n",
                "# Check if it's running\n",
                "import httpx\n",
                "try:\n",
                "    r = httpx.get(\"http://localhost:8000/health\", timeout=5)\n",
                "    print(f\"‚úÖ Whisper server running: {r.json()}\")\n",
                "except:\n",
                "    print(\"‚è≥ Still loading... wait a few more seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Create & Run Agent with Custom Whisper STT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile agent_v10.py\n",
                "\"\"\"LiveKit Voice Agent v10: Self-hosted Whisper API ‚Üí Gemini ‚Üí Soprano TTS\"\"\"\n",
                "\n",
                "import asyncio\n",
                "import os\n",
                "import re\n",
                "import io\n",
                "import numpy as np\n",
                "import httpx\n",
                "from typing import AsyncIterable\n",
                "\n",
                "from livekit import agents, rtc\n",
                "from livekit.agents import Agent, AgentSession, ModelSettings, cli, stt\n",
                "from livekit.plugins import google, silero\n",
                "\n",
                "WHISPER_API = \"http://localhost:8000\"\n",
                "SOPRANO = None\n",
                "\n",
                "\n",
                "def load_soprano():\n",
                "    global SOPRANO\n",
                "    if SOPRANO is None:\n",
                "        print(\"Loading Soprano TTS...\")\n",
                "        from soprano import SopranoTTS\n",
                "        SOPRANO = SopranoTTS(device=\"cuda\")\n",
                "        print(\"‚úÖ Soprano TTS ready\")\n",
                "\n",
                "\n",
                "class VoiceAgent(Agent):\n",
                "    def __init__(self):\n",
                "        super().__init__(instructions=\"You are a helpful voice assistant. Keep responses short, 1-2 sentences.\")\n",
                "        self._sent_re = re.compile(r\"(.+?[.!?]\\s+|.+?\\n+)\", re.DOTALL)\n",
                "        self._http_client = httpx.AsyncClient(timeout=30)\n",
                "\n",
                "    async def stt_node(self, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings):\n",
                "        \"\"\"Custom STT using self-hosted Whisper API\"\"\"\n",
                "        async def _transcribe():\n",
                "            # Collect all audio frames\n",
                "            chunks = []\n",
                "            async for frame in audio:\n",
                "                # Each frame has int16 data\n",
                "                chunks.append(frame.data)\n",
                "            \n",
                "            if not chunks:\n",
                "                yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "                return\n",
                "            \n",
                "            # Combine all audio data\n",
                "            audio_bytes = b\"\".join(chunks)\n",
                "            \n",
                "            # Call Whisper API\n",
                "            try:\n",
                "                files = {\"audio\": (\"audio.raw\", audio_bytes, \"application/octet-stream\")}\n",
                "                response = await self._http_client.post(f\"{WHISPER_API}/transcribe\", files=files)\n",
                "                result = response.json()\n",
                "                text = result.get(\"text\", \"\").strip()\n",
                "                \n",
                "                print(f\"üé§ User: {text}\")\n",
                "                \n",
                "                if text:\n",
                "                    yield stt.SpeechEvent(\n",
                "                        type=stt.SpeechEventType.FINAL_TRANSCRIPT,\n",
                "                        alternatives=[stt.SpeechData(text=text)],\n",
                "                    )\n",
                "            except Exception as e:\n",
                "                print(f\"STT error: {e}\")\n",
                "            \n",
                "            yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "        \n",
                "        return _transcribe()\n",
                "\n",
                "    async def tts_node(self, text: AsyncIterable[str], model_settings: ModelSettings):\n",
                "        \"\"\"Custom TTS using Soprano\"\"\"\n",
                "        buffer = \"\"\n",
                "        sr, spf = 32000, 640\n",
                "\n",
                "        def to_frames(pcm: np.ndarray):\n",
                "            pcm = np.clip(pcm, -1.0, 1.0)\n",
                "            pcm_i16 = (pcm * 32767).astype(np.int16)\n",
                "            for i in range(0, len(pcm_i16), spf):\n",
                "                chunk = pcm_i16[i:i+spf]\n",
                "                if len(chunk) < spf:\n",
                "                    chunk = np.pad(chunk, (0, spf - len(chunk)))\n",
                "                yield rtc.AudioFrame(\n",
                "                    data=chunk.tobytes(),\n",
                "                    sample_rate=sr,\n",
                "                    num_channels=1,\n",
                "                    samples_per_channel=spf\n",
                "                )\n",
                "\n",
                "        async def speak(sentence: str):\n",
                "            sentence = sentence.strip()\n",
                "            if not sentence:\n",
                "                return\n",
                "            print(f\"üîä Speaking: {sentence}\")\n",
                "            try:\n",
                "                for chunk in SOPRANO.infer_stream(sentence, chunk_size=1):\n",
                "                    pcm = np.asarray(chunk, dtype=np.float32)\n",
                "                    for frame in to_frames(pcm):\n",
                "                        yield frame\n",
                "            except Exception as e:\n",
                "                print(f\"TTS error: {e}\")\n",
                "\n",
                "        async for delta in text:\n",
                "            buffer += delta\n",
                "            while (m := self._sent_re.match(buffer)):\n",
                "                sentence = m.group(1)\n",
                "                buffer = buffer[len(sentence):]\n",
                "                async for frame in speak(sentence):\n",
                "                    yield frame\n",
                "        if buffer.strip():\n",
                "            async for frame in speak(buffer):\n",
                "                yield frame\n",
                "\n",
                "\n",
                "async def entrypoint(ctx: agents.JobContext):\n",
                "    # Check Whisper API is running\n",
                "    try:\n",
                "        async with httpx.AsyncClient() as client:\n",
                "            r = await client.get(f\"{WHISPER_API}/health\")\n",
                "            print(f\"‚úÖ Whisper API: {r.json()}\")\n",
                "    except:\n",
                "        print(\"‚ùå Whisper API not running! Start it first.\")\n",
                "        return\n",
                "    \n",
                "    # Load Soprano TTS (only model in this process)\n",
                "    load_soprano()\n",
                "    \n",
                "    # Connect to room\n",
                "    await ctx.connect()\n",
                "    print(f\"‚úÖ Connected to room: {ctx.room.name}\")\n",
                "    \n",
                "    # Load VAD\n",
                "    print(\"Loading Silero VAD...\")\n",
                "    vad = silero.VAD.load(min_speech_duration=0.05, min_silence_duration=0.4)\n",
                "    print(\"‚úÖ VAD ready\")\n",
                "    \n",
                "    agent = VoiceAgent()\n",
                "    \n",
                "    session = AgentSession(\n",
                "        turn_detection=\"vad\",\n",
                "        vad=vad,\n",
                "        llm=google.LLM(model=\"gemini-2.0-flash\"),\n",
                "        # STT and TTS handled by custom nodes in VoiceAgent\n",
                "    )\n",
                "    \n",
                "    await session.start(agent=agent, room=ctx.room)\n",
                "    print(\"\\n\" + \"=\"*50)\n",
                "    print(\"üé§ LISTENING... Speak now!\")\n",
                "    print(\"=\"*50 + \"\\n\")\n",
                "    \n",
                "    # Keep alive\n",
                "    disconnect_event = asyncio.Event()\n",
                "    \n",
                "    @ctx.room.on(\"disconnected\")\n",
                "    def on_disconnect():\n",
                "        print(\"Room disconnected\")\n",
                "        disconnect_event.set()\n",
                "    \n",
                "    await disconnect_event.wait()\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    cli.run_app(\n",
                "        agents.WorkerOptions(\n",
                "            entrypoint_fnc=entrypoint,\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python agent_v10.py start"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üîß Architecture\n",
                "```\n",
                "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "‚îÇ  Whisper API Server (8000)  ‚îÇ  ‚Üê Separate process\n",
                "‚îÇ  - Faster Whisper (GPU)     ‚îÇ\n",
                "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "            ‚Üë HTTP\n",
                "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "‚îÇ     LiveKit Agent           ‚îÇ\n",
                "‚îÇ  - Soprano TTS (GPU)        ‚îÇ  ‚Üê Only loads TTS\n",
                "‚îÇ  - Gemini LLM (API)         ‚îÇ\n",
                "‚îÇ  - Silero VAD (CPU)         ‚îÇ\n",
                "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "```\n",
                "\n",
                "## Benefits\n",
                "- ‚úÖ No external API keys needed for STT\n",
                "- ‚úÖ Models in separate processes (better memory)\n",
                "- ‚úÖ Full control over Whisper model\n",
                "- ‚úÖ Can swap Whisper models (tiny/base/small)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# To stop the Whisper server when done:\n",
                "# whisper_process.terminate()"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}