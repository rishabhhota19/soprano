{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¤ LiveKit Voice Agent v6\n",
                "\n",
                "**Whisper STT â†’ Gemini Flash â†’ Soprano TTS**\n",
                "\n",
                "Fixed: Agent now stays alive and processes audio properly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q \"livekit-agents[google,silero]~=1.3\" faster-whisper soprano-tts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "os.environ[\"LIVEKIT_URL\"] = \"wss://test-jllkasbg.livekit.cloud\"\n",
                "os.environ[\"LIVEKIT_API_KEY\"] = \"APIFnsAaWh3eFdR\"\n",
                "os.environ[\"LIVEKIT_API_SECRET\"] = \"WabCvkbupgaGfV7JQKBdZNDlYXuRFrr9jZcu7HTFdfG\"\n",
                "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD9sGx9FmvzIl7NtgU7vdwJVgs7NohSSqI\"\n",
                "os.environ[\"HF_HOME\"] = \"/content/hf_cache\"\n",
                "\n",
                "print(\"âœ… Credentials set\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile agent_v6.py\n",
                "\"\"\"LiveKit Voice Agent v6: Whisper â†’ Gemini Flash â†’ Soprano\"\"\"\n",
                "\n",
                "import asyncio\n",
                "import os\n",
                "import re\n",
                "import numpy as np\n",
                "from typing import AsyncIterable\n",
                "\n",
                "from livekit import agents, rtc\n",
                "from livekit.agents import Agent, AgentSession, ModelSettings, stt, cli\n",
                "from livekit.plugins import google, silero\n",
                "\n",
                "# Global models\n",
                "WHISPER = None\n",
                "SOPRANO = None\n",
                "VAD = None\n",
                "\n",
                "\n",
                "def load_models():\n",
                "    global WHISPER, SOPRANO, VAD\n",
                "    \n",
                "    if WHISPER is None:\n",
                "        print(\"Loading Faster Whisper...\")\n",
                "        from faster_whisper import WhisperModel\n",
                "        WHISPER = WhisperModel(\"tiny\", device=\"cuda\", compute_type=\"float16\")\n",
                "        print(\"âœ… Whisper\")\n",
                "    \n",
                "    if SOPRANO is None:\n",
                "        print(\"Loading Soprano TTS...\")\n",
                "        from soprano import SopranoTTS\n",
                "        SOPRANO = SopranoTTS(device=\"cuda\")\n",
                "        print(\"âœ… Soprano\")\n",
                "    \n",
                "    if VAD is None:\n",
                "        print(\"Loading Silero VAD...\")\n",
                "        VAD = silero.VAD.load(min_speech_duration=0.05, min_silence_duration=0.35, force_cpu=True)\n",
                "        print(\"âœ… VAD\")\n",
                "    \n",
                "    print(\"ðŸŽ‰ All models ready!\")\n",
                "\n",
                "\n",
                "class VoiceAgent(Agent):\n",
                "    def __init__(self):\n",
                "        super().__init__(instructions=\"You are a helpful voice assistant. Be concise.\")\n",
                "        self._sent_re = re.compile(r\"(.+?[.!?]\\s+|.+?\\n+)\", re.DOTALL)\n",
                "\n",
                "    async def stt_node(self, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings):\n",
                "        async def _transcribe():\n",
                "            chunks = []\n",
                "            async for frame in audio:\n",
                "                samples = np.frombuffer(frame.data, dtype=np.int16).astype(np.float32) / 32768.0\n",
                "                chunks.append(samples)\n",
                "            if not chunks:\n",
                "                yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "                return\n",
                "            audio_data = np.concatenate(chunks)\n",
                "            segments, _ = WHISPER.transcribe(audio_data, beam_size=1, language=\"en\")\n",
                "            text = \" \".join(s.text for s in segments).strip()\n",
                "            print(f\"ðŸŽ¤ User: {text}\")\n",
                "            if text:\n",
                "                yield stt.SpeechEvent(\n",
                "                    type=stt.SpeechEventType.FINAL_TRANSCRIPT,\n",
                "                    alternatives=[stt.SpeechData(text=text)],\n",
                "                )\n",
                "            yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "        return _transcribe()\n",
                "\n",
                "    async def tts_node(self, text: AsyncIterable[str], model_settings: ModelSettings):\n",
                "        buffer = \"\"\n",
                "        sr, spf = 32000, 640\n",
                "\n",
                "        def to_frames(pcm: np.ndarray):\n",
                "            pcm = np.clip(pcm, -1.0, 1.0)\n",
                "            pcm_i16 = (pcm * 32767).astype(np.int16)\n",
                "            for i in range(0, len(pcm_i16), spf):\n",
                "                chunk = pcm_i16[i:i+spf]\n",
                "                if len(chunk) < spf:\n",
                "                    chunk = np.pad(chunk, (0, spf - len(chunk)))\n",
                "                yield rtc.AudioFrame(\n",
                "                    data=chunk.tobytes(),\n",
                "                    sample_rate=sr,\n",
                "                    num_channels=1,\n",
                "                    samples_per_channel=spf\n",
                "                )\n",
                "\n",
                "        async def speak(sentence: str):\n",
                "            print(f\"ðŸ”Š Agent: {sentence.strip()}\")\n",
                "            for chunk in SOPRANO.infer_stream(sentence, chunk_size=1):\n",
                "                pcm = np.asarray(chunk, dtype=np.float32)\n",
                "                for frame in to_frames(pcm):\n",
                "                    yield frame\n",
                "\n",
                "        async for delta in text:\n",
                "            buffer += delta\n",
                "            while (m := self._sent_re.match(buffer)):\n",
                "                sentence = m.group(1)\n",
                "                buffer = buffer[len(sentence):]\n",
                "                async for frame in speak(sentence):\n",
                "                    yield frame\n",
                "        if buffer.strip():\n",
                "            async for frame in speak(buffer):\n",
                "                yield frame\n",
                "\n",
                "\n",
                "async def entrypoint(ctx: agents.JobContext):\n",
                "    # Load models\n",
                "    load_models()\n",
                "    \n",
                "    # Connect to room first and wait\n",
                "    await ctx.connect()\n",
                "    print(f\"âœ… Connected to room: {ctx.room.name}\")\n",
                "    \n",
                "    agent = VoiceAgent()\n",
                "    \n",
                "    session = AgentSession(\n",
                "        turn_detection=\"vad\",\n",
                "        vad=VAD,\n",
                "        llm=google.LLM(model=\"gemini-2.0-flash\"),\n",
                "    )\n",
                "    \n",
                "    # Start session\n",
                "    await session.start(agent=agent, room=ctx.room)\n",
                "    print(\"ðŸŽ¤ Listening... (speak now)\")\n",
                "    \n",
                "    # Keep agent alive until room closes\n",
                "    await session.wait()\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    cli.run_app(\n",
                "        agents.WorkerOptions(\n",
                "            entrypoint_fnc=entrypoint,\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run with 'start' mode instead of 'dev' to avoid hot-reload issues\n",
                "!python agent_v6.py start"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Changes in v6:\n",
                "\n",
                "1. **`await ctx.connect()`** - Wait for room connection before starting session\n",
                "2. **`await session.wait()`** - Keep agent alive until session ends\n",
                "3. **Using `start` instead of `dev`** - Avoids hot-reload killing processes\n",
                "\n",
                "## Test:\n",
                "1. Wait for \"ðŸŽ¤ Listening...\"\n",
                "2. Join http://localhost:3000\n",
                "3. Speak and wait for response"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}