{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83c\udf99\ufe0f Soprano Production-Grade Full-Duplex Agent\n",
                "\n",
                "This notebook implements a high-performance **Speech-to-Speech** agent using:\n",
                "- **Server**: FastAPI + WebSockets (Full Duplex)\n",
                "- **STT**: Faster-Whisper (GPU optimized)\n",
                "- **TTS**: Soprano (Streaming, Low Latency)\n",
                "- **VAD**: Silero VAD (Fast CPU)\n",
                "- **Transport**: Binary PCM over WebSockets\n",
                "- **Client**: WebRTC-style microphone capture with **Echo Cancellation** (AEC)\n",
                "\n",
                "### Architecture\n",
                "1. **Browser** captures audio -> sends PCM to Server.\n",
                "2. **Server** detects speech (VAD) -> **Interruption Spike** (stops TTS) -> STT -> LLM -> TTS Stream.\n",
                "3. **Browser** receives PCM -> Queues for playback -> Flushes queue on interruption signal.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 1. \ud83d\udce6 Setup & Installation\n",
                "#@markdown **Run this cell first, then RESTART RUNTIME.**\n",
                "\n",
                "print(\"\ud83d\udd27 Installing dependencies...\")\n",
                "\n",
                "# 0. LOCK NUMPY VERSION (Disabled)\n",
                "# print(\"\ud83d\udccc Locking NumPy to 1.26.4...\")\n",
                "# !pip uninstall numpy -y --quiet 2>/dev/null\n",
                "# !pip install \"numpy==1.26.4\" --quiet\n",
                "\n",
                "# 1. Clone Soprano\n",
                "!git clone https://github.com/ekwek1/soprano.git 2>/dev/null || echo \"Soprano already cloned\"\n",
                "%cd soprano\n",
                "\n",
                "# 2. Install Soprano & Core Deps\n",
                "!pip install -e . --quiet\n",
                "!pip install transformers huggingface_hub scipy unidecode --quiet\n",
                "\n",
                "# 3. Install Server & Agent Deps\n",
                "!pip install fastapi uvicorn[standard] websockets soundfile --quiet\n",
                "!pip install faster-whisper --quiet\n",
                "\n",
                "# 4. Install Cloudflared for Tunneling\n",
                "!pip install pycloudflared --quiet\n",
                "\n",
                "# 5. Force Reinstall NumPy safely at the end (Disabled)\n",
                "# !pip install \"numpy==1.26.4\" --force-reinstall --quiet\n",
                "\n",
                "print(\"\u2705 Installation complete!\")\n",
                "print(\"\u26a0\ufe0f  IMPORTANT: Go to 'Runtime -> Restart runtime' now!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd /content/soprano"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 2. \ud83d\udcdd Create Server Code (app.py)\n",
                "#@markdown Writes the FastAPI server code to `app.py`.\n",
                "\n",
                "# Ensure correct directory\n",
                "import os\n",
                "if os.path.isdir('/content/soprano'):\n",
                "    os.chdir('/content/soprano')\n",
                "    print(\"\ud83d\udcc2 Changed directory to /content/soprano\")\n",
                "\n",
                "code = '''\nimport asyncio\nimport json\nimport time\nfrom dataclasses import dataclass\nfrom typing import Optional, Deque\nfrom collections import deque\nimport os\nimport sys\n\nimport numpy as np\nimport torch\nfrom fastapi import FastAPI, WebSocket\nfrom fastapi.responses import HTMLResponse\nfrom faster_whisper import WhisperModel\nfrom starlette.websockets import WebSocketDisconnect\nfrom contextlib import asynccontextmanager\n\n# ---- Soprano ----\ntry:\n    from soprano import SopranoTTS\nexcept ImportError:\n    sys.path.append(os.getcwd())\n    from soprano import SopranoTTS\n\n# ---- Audio config ----\nIN_SR = 16000\nOUT_SR = 32000\n\n# ---- VAD (Silero) ----\ntorch.set_num_threads(1)\nvad_model, vad_utils = torch.hub.load(repo_or_dir=\"snakers4/silero-vad\", model=\"silero_vad\", trust_repo=True)\n(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = vad_utils\n\n# ---- Preload models at startup ----\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    # Startup: Load models BEFORE accepting any connections\n    print(\"\ud83d\udd04 Preloading Soprano TTS...\")\n    app.state.tts = SopranoTTS(device=\"cuda\", backend=\"auto\")\n    print(\"\u2705 Soprano loaded!\")\n    \n    print(\"\ud83d\udd04 Preloading Whisper STT...\")\n    app.state.whisper = WhisperModel(\"base\", device=\"cuda\", compute_type=\"float16\")\n    print(\"\u2705 Whisper loaded!\")\n    \n    print(\"\ud83d\udfe2 Server ready to accept connections!\")\n    yield\n    # Shutdown (cleanup if needed)\n    print(\"Server shutting down...\")\n\napp = FastAPI(lifespan=lifespan)\n\n@dataclass\nclass SessionState:\n    speech_buf: Deque[np.ndarray]\n    vad: VADIterator\n    in_speech: bool\n    tts_task: Optional[asyncio.Task]\n    tts_cancel: asyncio.Event\n\ndef pcm16_to_float32(pcm: bytes) -> np.ndarray:\n    x = np.frombuffer(pcm, dtype=np.int16).astype(np.float32)\n    return (x / 32768.0).clip(-1.0, 1.0)\n\ndef float32_to_pcm16(x: np.ndarray) -> bytes:\n    x = np.clip(x, -1.0, 1.0)\n    i16 = (x * 32767.0).astype(np.int16)\n    return i16.tobytes()\n\ndef generate_response_text(user_text: str) -> str:\n    return f\"I heard you say: {user_text}. This is a full duplex test.\"\n\nasync def safe_send_text(ws: WebSocket, payload: dict) -> bool:\n    \"\"\"Best-effort send that doesn't crash on disconnect.\"\"\"\n    try:\n        await ws.send_text(json.dumps(payload))\n        return True\n    except (WebSocketDisconnect, RuntimeError, asyncio.CancelledError):\n        return False\n\nasync def safe_send_bytes(ws: WebSocket, data: bytes) -> bool:\n    \"\"\"Best-effort send bytes that doesn't crash on disconnect.\"\"\"\n    try:\n        await ws.send_bytes(data)\n        return True\n    except (WebSocketDisconnect, RuntimeError, asyncio.CancelledError):\n        return False\n\nasync def stream_soprano_tts(ws: WebSocket, tts: SopranoTTS, text: str, st: SessionState):\n    \"\"\"Stream TTS chunks to client. Supports cancellation for barge-in.\"\"\"\n    try:\n        if not await safe_send_text(ws, {\"type\": \"tts_start\", \"sample_rate\": OUT_SR}):\n            return\n\n        for chunk in tts.infer_stream(text, chunk_size=1, temperature=0.0):\n            if st.tts_cancel.is_set():\n                break\n\n            if hasattr(chunk, \"detach\"):\n                chunk = chunk.detach().cpu().numpy()\n\n            chunk = np.asarray(chunk, dtype=np.float32).reshape(-1)\n            if not await safe_send_bytes(ws, float32_to_pcm16(chunk)):\n                break\n            await asyncio.sleep(0)\n\n        await safe_send_text(ws, {\"type\": \"tts_end\"})\n    except asyncio.CancelledError:\n        pass  # Clean exit on cancellation\n\nasync def cancel_tts(ws: WebSocket, st: SessionState):\n    \"\"\"Server-side cancel + client-side flush (best-effort).\"\"\"\n    st.tts_cancel.set()\n    if st.tts_task and not st.tts_task.done():\n        st.tts_task.cancel()\n        try:\n            await st.tts_task\n        except (asyncio.CancelledError, Exception):\n            pass\n    st.tts_task = None\n    await safe_send_text(ws, {\"type\": \"stop_audio\"})\n\n@app.get(\"/\")\nasync def get():\n    with open(\"index.html\", \"r\") as f:\n        return HTMLResponse(f.read())\n\n@app.websocket(\"/ws\")\nasync def ws_endpoint(ws: WebSocket):\n    await ws.accept()\n    print(\"\ud83d\udd17 Client connected!\")\n\n    # Models are already loaded at startup\n    tts = app.state.tts\n    whisper = app.state.whisper\n    vad_it = VADIterator(vad_model, sampling_rate=IN_SR)\n\n    st = SessionState(\n        speech_buf=deque(),\n        vad=vad_it,\n        in_speech=False,\n        tts_task=None,\n        tts_cancel=asyncio.Event(),\n    )\n\n    # Hello message\n    hello = \"I'm online. You can speak to me, and interrupt me, at any time.\"\n    st.tts_cancel.clear()\n    st.tts_task = asyncio.create_task(stream_soprano_tts(ws, tts, hello, st))\n\n    try:\n        async for pcm in ws.iter_bytes():\n            x = pcm16_to_float32(pcm)\n            tx = torch.from_numpy(x)\n\n            speech_event = st.vad(tx)\n\n            if speech_event:\n                if speech_event.get(\"start\"):\n                    if not st.in_speech:\n                        st.in_speech = True\n                        print(\"[VAD] Speech Start -> Interrupting\")\n                        await cancel_tts(ws, st)\n                \n                if speech_event.get(\"end\"):\n                    if st.in_speech:\n                        st.in_speech = False\n                        print(\"[VAD] Speech End -> Transcribing\")\n                        \n                        if len(st.speech_buf) > 0:\n                            utter = np.concatenate(list(st.speech_buf))\n                            st.speech_buf.clear()\n\n                            segments, _ = whisper.transcribe(utter, beam_size=1, vad_filter=False)\n                            user_text = \" \".join([s.text.strip() for s in segments]).strip()\n                            \n                            if user_text:\n                                await safe_send_text(ws, {\"type\": \"user_text\", \"text\": user_text})\n                                \n                                resp = generate_response_text(user_text)\n                                await safe_send_text(ws, {\"type\": \"agent_text\", \"text\": resp})\n\n                                st.tts_cancel.clear()\n                                st.tts_task = asyncio.create_task(stream_soprano_tts(ws, tts, resp, st))\n\n            if st.in_speech:\n                st.speech_buf.append(x)\n\n    except WebSocketDisconnect:\n        print(\"\ud83d\udc4b Client disconnected (normal)\")\n    except asyncio.CancelledError:\n        print(\"\u26a0\ufe0f Connection cancelled\")\n    finally:\n        st.tts_cancel.set()\n        if st.tts_task and not st.tts_task.done():\n            st.tts_task.cancel()\n            try:\n                await st.tts_task\n            except (asyncio.CancelledError, Exception):\n                pass\n        print(\"\ud83e\uddf9 Session cleanup complete\")\n'''\n",
                "\n",
                "with open(\"app.py\", \"w\") as f:\n",
                "    f.write(code)\n",
                "\n",
                "print(\"\u2705 app.py created (with preloaded models + disconnect-safe handling)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 3. \ud83d\udcdd Create Client Code (index.html)\n",
                "#@markdown Writes the WebRTC client code.\n",
                "\n",
                "html_code = \"\"\"\n",
                "<!doctype html>\n",
                "<html>\n",
                "<head>\n",
                "  <meta charset=\\\"utf-8\\\"/>\n",
                "  <title>Soprano Full Duplex</title>\n",
                "  <style>\n",
                "    body { font-family: system-ui; max-width: 800px; margin: 2rem auto; padding: 0 1rem; background: #f4f4f4; }\n",
                "    .container { background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }\n",
                "    button { font-size: 1.2rem; padding: 10px 20px; cursor: pointer; background: #007bff; color: white; border: none; border-radius: 5px; }\n",
                "    button:disabled { background: #ccc; }\n",
                "    #status { margin-top: 1rem; font-weight: bold; color: #555; }\n",
                "    #log { background: #1e1e1e; color: #0f0; padding: 1rem; border-radius: 5px; height: 300px; overflow-y: auto; font-family: monospace; margin-top: 1rem; }\n",
                "  </style>\n",
                "</head>\n",
                "<body>\n",
                "<div class=\\\"container\\\">\n",
                "  <h2>\ud83c\udf99\ufe0f Soprano Full Duplex Agent</h2>\n",
                "  <p>Speak naturally. Interrupt anytime.</p>\n",
                "  <button id=\\\"go\\\">Start Conversation</button>\n",
                "  <div id=\\\"status\\\">Disconnected</div>\n",
                "  <div id=\\\"log\\\"></div>\n",
                "</div>\n",
                "<script>\n",
                "// Detect environment to set WS URL automatically\n",
                "const proto = window.location.protocol === 'https:' ? 'wss' : 'ws';\n",
                "const WS_URL = `${proto}://${window.location.host}/ws`;\n",
                "\n",
                "const logEl = document.getElementById(\\\"log\\\");\n",
                "const log = (s) => {\n",
                "  logEl.textContent += `> ${s}\\n`;\n",
                "  logEl.scrollTop = logEl.scrollHeight;\n",
                "};\n",
                "\n",
                "let audioCtx, source, processor;\n",
                "let ttsQueue = [];\n",
                "let playing = false;\n",
                "let outSR = 32000;\n",
                "\n",
                "function clearPlayback() {\n",
                "  ttsQueue = [];\n",
                "  playing = false;\n",
                "  // Note: Web Audio API buffers can't be strictly \\\"cancelled\\\" once scheduled easily without replacing nodes,\n",
                "  // but clearing the queue prevents future chunks. For strictly immediate stop, we'd close/reopen context or disconnect node.\n",
                "  // For this demo, clearing queue + state is sufficient for perceived interruption.\n",
                "}\n",
                "\n",
                "async function pumpPlayback() {\n",
                "  if (playing) return;\n",
                "  playing = true;\n",
                "\n",
                "  while (ttsQueue.length > 0) {\n",
                "    if (!playing) break; // Check interrupt\n",
                "    \n",
                "    const pcm16 = ttsQueue.shift();\n",
                "    const i16 = new Int16Array(pcm16);\n",
                "    const f32 = new Float32Array(i16.length);\n",
                "    for (let i=0; i<i16.length; i++) f32[i] = i16[i] / 32768.0;\n",
                "\n",
                "    const buf = audioCtx.createBuffer(1, f32.length, outSR);\n",
                "    buf.getChannelData(0).set(f32);\n",
                "\n",
                "    const src = audioCtx.createBufferSource();\n",
                "    src.buffer = buf;\n",
                "    src.connect(audioCtx.destination);\n",
                "    src.start();\n",
                "\n",
                "    await new Promise(res => src.onended = res);\n",
                "  }\n",
                "  playing = false;\n",
                "}\n",
                "\n",
                "document.getElementById(\\\"go\\\").onclick = async () => {\n",
                "  // 1. Audio Context\n",
                "  audioCtx = new (window.AudioContext || window.webkitAudioContext)();\n",
                "  \n",
                "  // 2. WebSocket\n",
                "  document.getElementById(\\\"status\\\").textContent = \\\"Connecting...\\\";\n",
                "  const ws = new WebSocket(WS_URL);\n",
                "  ws.binaryType = \\\"arraybuffer\\\";\n",
                "\n",
                "  ws.onopen = async () => {\n",
                "    document.getElementById(\\\"status\\\").textContent = \\\"Connected - Listening\\\";\n",
                "    document.getElementById(\\\"go\\\").disabled = true;\n",
                "    log(\\\"Ws Connected. Requesting Mic...\\\");\n",
                "\n",
                "    // 3. Mic Capture with AEC (Critical for full duplex)\n",
                "    const stream = await navigator.mediaDevices.getUserMedia({\n",
                "      audio: {\n",
                "        channelCount: 1,\n",
                "        sampleRate: 16000,\n",
                "        echoCancellation: true, \n",
                "        noiseSuppression: true,\n",
                "        autoGainControl: true\n",
                "      }\n",
                "    });\n",
                "\n",
                "    // 4. Processor (Worklet is better, but ScriptProcessor is easier for single-file demo)\n",
                "    source = audioCtx.createMediaStreamSource(stream);\n",
                "    processor = audioCtx.createScriptProcessor(512, 1, 1);\n",
                "\n",
                "    processor.onaudioprocess = (e) => {\n",
                "      if (ws.readyState !== WebSocket.OPEN) return;\n",
                "      \n",
                "      const input = e.inputBuffer.getChannelData(0);\n",
                "      // Float32 -> Int16\n",
                "      const pcm = new Int16Array(input.length);\n",
                "      for (let i=0; i<input.length; i++) {\n",
                "        let s = Math.max(-1, Math.min(1, input[i]));\n",
                "        pcm[i] = s < 0 ? s * 32768 : s * 32767;\n",
                "      }\n",
                "      ws.send(pcm.buffer);\n",
                "    };\n",
                "\n",
                "    source.connect(processor);\n",
                "    processor.connect(audioCtx.destination);\n",
                "    log(\\\"Mic active. Speak anytime!\\\");\n",
                "  };\n",
                "\n",
                "  ws.onmessage = (ev) => {\n",
                "    if (typeof ev.data === \\\"string\\\") {\n",
                "      const msg = JSON.parse(ev.data);\n",
                "      \n",
                "      if (msg.type === \\\"tts_start\\\") outSR = msg.sample_rate;\n",
                "      if (msg.type === \\\"stop_audio\\\") {\n",
                "        log(\\\"\ud83d\uded1 INTERRUPT Detected -> Clearing playback\\\");\n",
                "        clearPlayback();\n",
                "      }\n",
                "      if (msg.type === \\\"user_text\\\") log(\\\"User: \\\" + msg.text);\n",
                "      if (msg.type === \\\"agent_text\\\") log(\\\"Agent: \\\" + msg.text);\n",
                "      return;\n",
                "    }\n",
                "\n",
                "    // Binary Audio\n",
                "    ttsQueue.push(ev.data);\n",
                "    pumpPlayback();\n",
                "  };\n",
                "\n",
                "  ws.onclose = () => {\n",
                "    document.getElementById(\\\"status\\\").textContent = \\\"Disconnected\\\";\n",
                "    log(\\\"Disconnected\\\");\n",
                "  };\n",
                "};\n",
                "</script>\n",
                "</body>\n",
                "</html>\n",
                "\"\"\"\n",
                "\n",
                "with open(\"index.html\", \"w\") as f:\n",
                "    f.write(html_code)\n",
                "\n",
                "print(\"\u2705 index.html created\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 4. \ud83d\ude80 Launch Server\n",
                "#@markdown Starts the FastAPI server and exposes it via Cloudflare Tunnel.\n",
                "#@markdown Click the **trycloudflare** link that appears to access the UI.\n",
                "\n",
                "import os\n",
                "import threading\n",
                "import time\n",
                "from pycloudflared import try_cloudflare\n",
                "\n",
                "# 1. Start Tunnel\n",
                "public_url = try_cloudflare(port=8000)\n",
                "print(f\"\\n\ud83c\udf0d Public URL: {public_url}\\n\")\n",
                "\n",
                "# 2. Run Uvicorn (Blocking)\n",
                "print(\"\ud83d\ude80 Starting Uvicorn Server... (This buffer will capture logs)\")\n",
                "!uvicorn app:app --host 0.0.0.0 --port 8000"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}