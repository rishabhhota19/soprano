{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "4d32a270",
            "metadata": {},
            "source": [
                "# ü§ñ Soprano Real-Time Voice Agent (Colab Version)\n",
                "\n",
                "This notebook runs a full-duplex conversational agent using **Soprano TTS** for output and **Gradio** for streaming audio I/O.\n",
                "\n",
                "**Features:**\n",
                "- **Real-time Streaming:** Snappy, low-latency responses.\n",
                "- **Barge-in Support:** The agent listens while speaking. If you interrupt, it stops talking.\n",
                "- **Mock Brain:** Uses a simulated STT/LLM for demonstration. You can plug in OpenAI/Groq easily.\n",
                "\n",
                "**Note:** If you see Numpy errors, restart the runtime after installation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7e143d1c",
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 1. Install Dependencies\n",
                "!git clone https://github.com/ekwek1/soprano.git\n",
                "%cd soprano\n",
                "!pip install -e .[lmdeploy] --quiet\n",
                "# Numpy 2.0 can cause issues, so we pin it to <2.0\n",
                "!pip install \"numpy<2.0\" gradio sounddevice scipy --upgrade --quiet\n",
                "print(\"Done!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#@title 2. Define the Agent\n",
                "import gradio as gr\n",
                "import numpy as np\n",
                "import time\n",
                "import queue\n",
                "import threading\n",
                "import random\n",
                "from soprano import SopranoTTS\n",
                "\n",
                "class MockBrain:\n",
                "    \"\"\"Simulates the Intelligence (STT -> LLM)\"\"\"\n",
                "    def generate(self, audio_data):\n",
                "        # In a real app, you would run Whisper STT on audio_data here\n",
                "        # Then send text to an LLM\n",
                "        responses = [\n",
                "            \"I hear you loud and clear. Soprano is fast!\",\n",
                "            \"That is very interesting. Please tell me more.\",\n",
                "            \"I stopped speaking because I heard you interrupt. This is full duplex.\",\n",
                "            \"The weather is nice in the cloud today.\",\n",
                "            \"Voice interfaces are the future of AI.\"\n",
                "        ]\n",
                "        return random.choice(responses)\n",
                "\n",
                "class ColabAgent:\n",
                "    def __init__(self):\n",
                "        print(\"Initializing Soprano (CUDA)...\")\n",
                "        try:\n",
                "            self.tts = SopranoTTS(backend='lmdeploy', device='cuda', cache_size_mb=100)\n",
                "        except Exception as e:\n",
                "            print(f\"Warning: Could not load CUDA backend ({e}). Falling back to CPU/Transformers.\")\n",
                "            self.tts = SopranoTTS(backend='transformers', device='cpu')\n",
                "        \n",
                "        self.brain = MockBrain()\n",
                "        \n",
                "        # State\n",
                "        self.audio_buffer = []\n",
                "        self.silence_start = None\n",
                "        self.is_speaking = False\n",
                "        self.user_is_speaking = False\n",
                "        self.interrupted = False\n",
                "\n",
                "        # Constants\n",
                "        self.SAMPLE_RATE = 32000\n",
                "        self.VAD_THRESHOLD = 0.05  # Energy threshold\n",
                "        self.SILENCE_DURATION = 0.8 # Seconds of silence to trigger response\n",
                "\n",
                "    def process_audio_stream(self, audio_chunk, state):\n",
                "        \"\"\"\n",
                "        Gradio calls this roughly every 0.1s with new microphone audio.\n",
                "        Returns: Audio output (or None if listening)\n",
                "        \"\"\"\n",
                "        if audio_chunk is None:\n",
                "            return None\n",
                "            \n",
                "        fs, data = audio_chunk\n",
                "        # Convert to standard format (float32, mono)\n",
                "        if data.dtype == np.int16:\n",
                "            data = data.astype(np.float32) / 32768.0\n",
                "        if len(data.shape) > 1:\n",
                "            data = np.mean(data, axis=1)\n",
                "            \n",
                "        rms = np.sqrt(np.mean(data**2))\n",
                "        \n",
                "        # --- VAD & State Logic ---\n",
                "        if rms > self.VAD_THRESHOLD:\n",
                "            if not self.user_is_speaking:\n",
                "                self.user_is_speaking = True\n",
                "                # Barge-in Trigger!\n",
                "                if self.is_speaking:\n",
                "                    self.interrupted = True \n",
                "                    print(\"[Barge-in detected] Stopping agent...\")\n",
                "            self.silence_start = None\n",
                "        elif self.user_is_speaking:\n",
                "            # Handled silence after speech\n",
                "            if self.silence_start is None:\n",
                "                self.silence_start = time.time()\n",
                "            \n",
                "            if time.time() - self.silence_start > self.SILENCE_DURATION:\n",
                "                # User finished speaking -> Trigger Response\n",
                "                self.user_is_speaking = False\n",
                "                self.silence_start = None\n",
                "                return self.trigger_response()\n",
                "\n",
                "        return None\n",
                "\n",
                "    def trigger_response(self):\n",
                "        \"\"\"Generates response audio generator\"\"\"\n",
                "        # Reset interruption flag\n",
                "        self.interrupted = False\n",
                "        self.is_speaking = True\n",
                "        \n",
                "        text = self.brain.generate(None)\n",
                "        print(f\"Agent replying: {text}\")\n",
                "        \n",
                "        # Streaming Inference\n",
                "        stream = self.tts.infer_stream(text)\n",
                "        \n",
                "        for chunk in stream:\n",
                "            # Check interruption\n",
                "            if self.interrupted:\n",
                "                print(\"Agent halted.\")\n",
                "                break\n",
                "                \n",
                "            chunk_np = chunk.cpu().numpy()\n",
                "            chunk_int16 = (chunk_np * 32767).astype(np.int16)\n",
                "            yield (self.SAMPLE_RATE, chunk_int16)\n",
                "            \n",
                "        self.is_speaking = False\n",
                "\n",
                "# Initialize\n",
                "agent = ColabAgent()\n",
                "\n",
                "# Gradio Interface\n",
                "with gr.Blocks(title=\"Real-Time Soprano Agent\") as demo:\n",
                "    gr.Markdown(\"## üéôÔ∏è Speak to Interrupt!\")\n",
                "    gr.Markdown(\"This agent uses VAD to detect when you speak. If you speak while it's talking, it stops.\")\n",
                "    \n",
                "    with gr.Row():\n",
                "        mic = gr.Audio(sources=[\"microphone\"], streaming=True, show_label=False)\n",
                "        speaker = gr.Audio(label=\"Agent Output\", streaming=True, autoplay=True, interactive=False)\n",
                "\n",
                "    # Connect streaming input to processing function\n",
                "    mic.stream(agent.process_audio_stream, inputs=[mic], outputs=[speaker], time_limit=60)\n",
                "\n",
                "demo.launch(share=True)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
