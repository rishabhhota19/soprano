{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¤ LiveKit Voice Agent v3\n",
                "\n",
                "**Faster Whisper STT â†’ Gemini LLM â†’ Soprano TTS**\n",
                "\n",
                "Single-process version for Colab."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q livekit-agents[google,silero]~=1.3\n",
                "!pip install -q faster-whisper soprano-tts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pre-load all models\n",
                "import os\n",
                "os.environ[\"HF_HOME\"] = \"/content/hf_cache\"\n",
                "\n",
                "print(\"Loading Whisper...\")\n",
                "from faster_whisper import WhisperModel\n",
                "WHISPER = WhisperModel(\"tiny\", device=\"cuda\", compute_type=\"float16\")\n",
                "print(\"âœ… Whisper\")\n",
                "\n",
                "print(\"Loading Soprano...\")\n",
                "from soprano import SopranoTTS  \n",
                "SOPRANO = SopranoTTS(device=\"cuda\")\n",
                "print(\"âœ… Soprano\")\n",
                "\n",
                "print(\"Loading VAD...\")\n",
                "from livekit.plugins import silero\n",
                "VAD = silero.VAD.load(min_speech_duration=0.05, min_silence_duration=0.35, force_cpu=True)\n",
                "print(\"âœ… VAD\")\n",
                "\n",
                "print(\"\\nðŸŽ‰ All models loaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# ========== REPLACE WITH YOUR CREDENTIALS ==========\n",
                "os.environ[\"LIVEKIT_URL\"] = \"wss://test-jllkasbg.livekit.cloud\"\n",
                "os.environ[\"LIVEKIT_API_KEY\"] = \"APIFnsAaWh3eFdR\"\n",
                "os.environ[\"LIVEKIT_API_SECRET\"] = \"WabCvkbupgaGfV7JQKBdZNDlYXuRFrr9jZcu7HTFdfG\"\n",
                "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD9sGx9FmvzIl7NtgU7vdwJVgs7NohSSqI\"\n",
                "# =====================================================\n",
                "\n",
                "print(\"âœ… Credentials set\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import asyncio\n",
                "import re\n",
                "import numpy as np\n",
                "from typing import AsyncIterable\n",
                "\n",
                "from livekit import agents, rtc, api\n",
                "from livekit.agents import Agent, AgentSession, ModelSettings, stt\n",
                "from livekit.plugins import google\n",
                "\n",
                "\n",
                "class VoiceAgent(Agent):\n",
                "    def __init__(self):\n",
                "        super().__init__(instructions=\"You are a helpful voice assistant. Be concise.\")\n",
                "        self._sent_re = re.compile(r\"(.+?[.!?]\\s+|.+?\\n+)\", re.DOTALL)\n",
                "\n",
                "    async def stt_node(self, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings):\n",
                "        \"\"\"Faster Whisper STT\"\"\"\n",
                "        async def _transcribe():\n",
                "            chunks = []\n",
                "            async for frame in audio:\n",
                "                samples = np.frombuffer(frame.data, dtype=np.int16).astype(np.float32) / 32768.0\n",
                "                chunks.append(samples)\n",
                "            if not chunks:\n",
                "                yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "                return\n",
                "            audio_data = np.concatenate(chunks)\n",
                "            segments, _ = WHISPER.transcribe(audio_data, beam_size=1, language=\"en\")\n",
                "            text = \" \".join(s.text for s in segments).strip()\n",
                "            print(f\"ðŸŽ¤ User: {text}\")\n",
                "            if text:\n",
                "                yield stt.SpeechEvent(type=stt.SpeechEventType.FINAL_TRANSCRIPT, alternatives=[stt.SpeechData(text=text)])\n",
                "            yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "        return _transcribe()\n",
                "\n",
                "    async def tts_node(self, text: AsyncIterable[str], model_settings: ModelSettings):\n",
                "        \"\"\"Soprano TTS\"\"\"\n",
                "        buffer = \"\"\n",
                "        sr, spf = 32000, 640\n",
                "        \n",
                "        def to_frames(pcm):\n",
                "            pcm = np.clip(pcm, -1.0, 1.0)\n",
                "            pcm_i16 = (pcm * 32767).astype(np.int16)\n",
                "            for i in range(0, len(pcm_i16), spf):\n",
                "                chunk = pcm_i16[i:i+spf]\n",
                "                if len(chunk) < spf:\n",
                "                    chunk = np.pad(chunk, (0, spf - len(chunk)))\n",
                "                yield rtc.AudioFrame(data=chunk.tobytes(), sample_rate=sr, num_channels=1, samples_per_channel=spf)\n",
                "\n",
                "        async def speak(sentence):\n",
                "            print(f\"ðŸ”Š Agent: {sentence.strip()}\")\n",
                "            for chunk in SOPRANO.infer_stream(sentence, chunk_size=1):\n",
                "                pcm = np.asarray(chunk, dtype=np.float32)\n",
                "                for frame in to_frames(pcm):\n",
                "                    yield frame\n",
                "\n",
                "        async for delta in text:\n",
                "            buffer += delta\n",
                "            while (m := self._sent_re.match(buffer)):\n",
                "                sentence = m.group(1)\n",
                "                buffer = buffer[len(sentence):]\n",
                "                async for frame in speak(sentence):\n",
                "                    yield frame\n",
                "        if buffer.strip():\n",
                "            async for frame in speak(buffer):\n",
                "                yield frame\n",
                "\n",
                "\n",
                "async def run_agent():\n",
                "    url = os.environ[\"LIVEKIT_URL\"]\n",
                "    api_key = os.environ[\"LIVEKIT_API_KEY\"]\n",
                "    api_secret = os.environ[\"LIVEKIT_API_SECRET\"]\n",
                "    \n",
                "    room_name = \"soprano-agent\"\n",
                "    lk_api = api.LiveKitAPI(url, api_key, api_secret)\n",
                "    await lk_api.room.create_room(api.CreateRoomRequest(name=room_name))\n",
                "    \n",
                "    token = api.AccessToken(api_key, api_secret)\n",
                "    token.with_identity(\"agent\").with_grants(api.VideoGrants(room_join=True, room=room_name))\n",
                "    \n",
                "    print(f\"\\nðŸ”— Join: https://agents-playground.livekit.io/#room={room_name}&url={url}\")\n",
                "    \n",
                "    room = rtc.Room()\n",
                "    await room.connect(url, token.to_jwt())\n",
                "    print(\"âœ… Connected\")\n",
                "    \n",
                "    agent = VoiceAgent()\n",
                "    session = AgentSession(\n",
                "        turn_detection=\"vad\",\n",
                "        vad=VAD,\n",
                "        # Use regular Gemini LLM (not Realtime API)\n",
                "        llm=google.LLM(model=\"gemini-2.0-flash\"),\n",
                "    )\n",
                "    \n",
                "    await session.start(agent=agent, room=room)\n",
                "    print(\"ðŸŽ¤ Listening... (interrupt kernel to stop)\\n\")\n",
                "    \n",
                "    try:\n",
                "        while True:\n",
                "            await asyncio.sleep(1)\n",
                "    except (KeyboardInterrupt, asyncio.CancelledError):\n",
                "        pass\n",
                "    finally:\n",
                "        await room.disconnect()\n",
                "        print(\"\\nðŸ‘‹ Disconnected\")\n",
                "\n",
                "\n",
                "await run_agent()"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}