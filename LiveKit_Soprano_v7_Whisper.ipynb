{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¤ LiveKit Voice Agent v7\n",
                "\n",
                "**OpenAI Whisper STT â†’ Gemini Flash â†’ Soprano TTS**\n",
                "\n",
                "Uses OpenAI Whisper API for reliable STT, Soprano for TTS."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q \"livekit-agents[google,silero,openai]~=1.3\" soprano-tts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# LiveKit credentials\n",
                "os.environ[\"LIVEKIT_URL\"] = \"wss://test-jllkasbg.livekit.cloud\"\n",
                "os.environ[\"LIVEKIT_API_KEY\"] = \"APIFnsAaWh3eFdR\"\n",
                "os.environ[\"LIVEKIT_API_SECRET\"] = \"WabCvkbupgaGfV7JQKBdZNDlYXuRFrr9jZcu7HTFdfG\"\n",
                "\n",
                "# Google Gemini\n",
                "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD9sGx9FmvzIl7NtgU7vdwJVgs7NohSSqI\"\n",
                "\n",
                "# ========== ADD YOUR OPENAI API KEY ==========\n",
                "os.environ[\"OPENAI_API_KEY\"] = \"sk-YOUR-OPENAI-API-KEY-HERE\"\n",
                "# =============================================\n",
                "\n",
                "os.environ[\"HF_HOME\"] = \"/content/hf_cache\"\n",
                "\n",
                "print(\"âœ… Credentials set\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile agent_v7.py\n",
                "\"\"\"LiveKit Voice Agent v7: OpenAI Whisper STT â†’ Gemini â†’ Soprano TTS\"\"\"\n",
                "\n",
                "import asyncio\n",
                "import os\n",
                "import re\n",
                "import numpy as np\n",
                "from typing import AsyncIterable\n",
                "\n",
                "from livekit import agents, rtc\n",
                "from livekit.agents import Agent, AgentSession, ModelSettings, cli\n",
                "from livekit.plugins import google, silero, openai as openai_plugin\n",
                "\n",
                "# Global TTS\n",
                "SOPRANO = None\n",
                "\n",
                "\n",
                "def load_soprano():\n",
                "    global SOPRANO\n",
                "    if SOPRANO is None:\n",
                "        print(\"Loading Soprano TTS...\")\n",
                "        from soprano import SopranoTTS\n",
                "        SOPRANO = SopranoTTS(device=\"cuda\")\n",
                "        print(\"âœ… Soprano TTS ready\")\n",
                "\n",
                "\n",
                "class VoiceAgent(Agent):\n",
                "    def __init__(self):\n",
                "        super().__init__(instructions=\"You are a helpful voice assistant. Keep responses short and conversational, 1-2 sentences max.\")\n",
                "        self._sent_re = re.compile(r\"(.+?[.!?]\\s+|.+?\\n+)\", re.DOTALL)\n",
                "\n",
                "    async def tts_node(self, text: AsyncIterable[str], model_settings: ModelSettings):\n",
                "        \"\"\"Custom TTS using Soprano\"\"\"\n",
                "        buffer = \"\"\n",
                "        sr, spf = 32000, 640  # 20ms frames at 32kHz\n",
                "\n",
                "        def to_frames(pcm: np.ndarray):\n",
                "            pcm = np.clip(pcm, -1.0, 1.0)\n",
                "            pcm_i16 = (pcm * 32767).astype(np.int16)\n",
                "            for i in range(0, len(pcm_i16), spf):\n",
                "                chunk = pcm_i16[i:i+spf]\n",
                "                if len(chunk) < spf:\n",
                "                    chunk = np.pad(chunk, (0, spf - len(chunk)))\n",
                "                yield rtc.AudioFrame(\n",
                "                    data=chunk.tobytes(),\n",
                "                    sample_rate=sr,\n",
                "                    num_channels=1,\n",
                "                    samples_per_channel=spf\n",
                "                )\n",
                "\n",
                "        async def speak(sentence: str):\n",
                "            sentence = sentence.strip()\n",
                "            if not sentence:\n",
                "                return\n",
                "            print(f\"ðŸ”Š Speaking: {sentence}\")\n",
                "            try:\n",
                "                for chunk in SOPRANO.infer_stream(sentence, chunk_size=1):\n",
                "                    pcm = np.asarray(chunk, dtype=np.float32)\n",
                "                    for frame in to_frames(pcm):\n",
                "                        yield frame\n",
                "            except Exception as e:\n",
                "                print(f\"âŒ TTS error: {e}\")\n",
                "\n",
                "        async for delta in text:\n",
                "            buffer += delta\n",
                "            # Process complete sentences\n",
                "            while (m := self._sent_re.match(buffer)):\n",
                "                sentence = m.group(1)\n",
                "                buffer = buffer[len(sentence):]\n",
                "                async for frame in speak(sentence):\n",
                "                    yield frame\n",
                "        # Flush remaining\n",
                "        if buffer.strip():\n",
                "            async for frame in speak(buffer):\n",
                "                yield frame\n",
                "\n",
                "\n",
                "async def entrypoint(ctx: agents.JobContext):\n",
                "    # Load Soprano TTS\n",
                "    load_soprano()\n",
                "    \n",
                "    # Connect to room\n",
                "    await ctx.connect()\n",
                "    print(f\"âœ… Connected to room: {ctx.room.name}\")\n",
                "    \n",
                "    # Load VAD\n",
                "    print(\"Loading Silero VAD...\")\n",
                "    vad = silero.VAD.load(min_speech_duration=0.05, min_silence_duration=0.4)\n",
                "    print(\"âœ… VAD ready\")\n",
                "    \n",
                "    agent = VoiceAgent()\n",
                "    \n",
                "    session = AgentSession(\n",
                "        turn_detection=\"vad\",\n",
                "        vad=vad,\n",
                "        stt=openai_plugin.STT(model=\"whisper-1\"),  # OpenAI Whisper API\n",
                "        llm=google.LLM(model=\"gemini-2.0-flash\"),  # Gemini for text generation\n",
                "        # TTS handled by custom tts_node in VoiceAgent\n",
                "    )\n",
                "    \n",
                "    # Set up session event handlers\n",
                "    @session.on(\"user_input_transcribed\")\n",
                "    def on_transcription(text):\n",
                "        print(f\"ðŸŽ¤ User: {text}\")\n",
                "    \n",
                "    # Start the session\n",
                "    await session.start(agent=agent, room=ctx.room)\n",
                "    print(\"ðŸŽ¤ Listening... speak now!\")\n",
                "    \n",
                "    # Keep alive until room disconnects\n",
                "    disconnect_event = asyncio.Event()\n",
                "    \n",
                "    @ctx.room.on(\"disconnected\")\n",
                "    def on_disconnect():\n",
                "        print(\"Room disconnected\")\n",
                "        disconnect_event.set()\n",
                "    \n",
                "    await disconnect_event.wait()\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    cli.run_app(\n",
                "        agents.WorkerOptions(\n",
                "            entrypoint_fnc=entrypoint,\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python agent_v7.py start"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ðŸ§ª Test\n",
                "\n",
                "1. Wait for \"ðŸŽ¤ Listening...\" message\n",
                "2. Open http://localhost:3000 (your local playground)\n",
                "3. Join the room and speak!\n",
                "\n",
                "## Pipeline\n",
                "```\n",
                "ðŸŽ™ï¸ You speak\n",
                "    â†“\n",
                "OpenAI Whisper API (STT)\n",
                "    â†“\n",
                "Gemini 2.0 Flash (LLM)\n",
                "    â†“\n",
                "Soprano TTS (Voice)\n",
                "    â†“\n",
                "ðŸ”Š Agent speaks\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}