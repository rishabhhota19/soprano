{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¤ LiveKit Voice Agent: Faster Whisper + Gemini + Soprano\n",
                "\n",
                "Complete working pipeline for Google Colab T4 GPU with all timeout fixes.\n",
                "\n",
                "| Component | Model |\n",
                "|-----------|-------|\n",
                "| **STT** | Faster Whisper (tiny) |\n",
                "| **LLM** | Gemini 2.5 Flash |\n",
                "| **TTS** | Soprano |\n",
                "| **VAD** | Silero |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q livekit-agents[google,silero]~=1.3\n",
                "!pip install -q faster-whisper\n",
                "!pip install -q soprano-tts"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Check GPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi\n",
                "\n",
                "import torch\n",
                "print(f\"\\nPyTorch CUDA: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Pre-Download Models (Run Once)\n",
                "\n",
                "This caches models so the agent doesn't timeout during startup."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ[\"HF_HOME\"] = \"/content/hf_cache\"\n",
                "\n",
                "print(\"Downloading Faster Whisper...\")\n",
                "from faster_whisper import WhisperModel\n",
                "whisper = WhisperModel(\"tiny\", device=\"cuda\", compute_type=\"float16\")\n",
                "del whisper\n",
                "print(\"âœ… Whisper cached\")\n",
                "\n",
                "print(\"Downloading Soprano TTS...\")\n",
                "from soprano import SopranoTTS\n",
                "soprano = SopranoTTS(device=\"cuda\")\n",
                "del soprano\n",
                "print(\"âœ… Soprano cached\")\n",
                "\n",
                "print(\"\\nðŸŽ‰ All models ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Set Credentials\n",
                "\n",
                "Get credentials from:\n",
                "- **LiveKit**: https://cloud.livekit.io â†’ Project â†’ API Keys\n",
                "- **Google**: https://aistudio.google.com/apikey"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# ========== REPLACE THESE ==========\n",
                "os.environ[\"LIVEKIT_URL\"] = \"wss://YOUR-PROJECT.livekit.cloud\"\n",
                "os.environ[\"LIVEKIT_API_KEY\"] = \"YOUR_API_KEY\"\n",
                "os.environ[\"LIVEKIT_API_SECRET\"] = \"YOUR_API_SECRET\"\n",
                "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_GOOGLE_API_KEY\"\n",
                "# ====================================\n",
                "\n",
                "os.environ[\"GEMINI_MODEL\"] = \"gemini-2.5-flash\"\n",
                "os.environ[\"SYSTEM_PROMPT\"] = \"You are a helpful voice assistant. Be concise.\"\n",
                "os.environ[\"HF_HOME\"] = \"/content/hf_cache\"\n",
                "\n",
                "print(\"âœ… Credentials set\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Create Agent Script"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile livekit_agent.py\n",
                "\"\"\"LiveKit Voice Agent: Faster Whisper STT â†’ Gemini â†’ Soprano TTS\"\"\"\n",
                "\n",
                "import os\n",
                "import re\n",
                "import numpy as np\n",
                "from typing import AsyncIterable, Optional, List\n",
                "\n",
                "from livekit import agents, rtc\n",
                "from livekit.agents import Agent, AgentSession, ModelSettings, stt, cli\n",
                "from livekit.agents.worker import WorkerOptions\n",
                "from livekit.agents.job import JobExecutorType\n",
                "from livekit.plugins import google, silero\n",
                "from google.genai.types import Modality\n",
                "\n",
                "from faster_whisper import WhisperModel\n",
                "from soprano import SopranoTTS\n",
                "\n",
                "\n",
                "class VoiceAgent(Agent):\n",
                "    def __init__(self, whisper: WhisperModel, soprano: SopranoTTS, instructions: str):\n",
                "        # FIX: Pass instructions to parent Agent class\n",
                "        super().__init__(instructions=instructions)\n",
                "        self._whisper = whisper\n",
                "        self._soprano = soprano\n",
                "        self._sent_re = re.compile(r\"(.+?[.!?]\\s+|.+?\\n+)\", re.DOTALL)\n",
                "\n",
                "    async def stt_node(\n",
                "        self, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings\n",
                "    ) -> Optional[AsyncIterable[stt.SpeechEvent]]:\n",
                "        async def _transcribe():\n",
                "            chunks = []\n",
                "            async for frame in audio:\n",
                "                samples = np.frombuffer(frame.data, dtype=np.int16).astype(np.float32) / 32768.0\n",
                "                chunks.append(samples)\n",
                "            \n",
                "            if not chunks:\n",
                "                yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "                return\n",
                "            \n",
                "            audio_data = np.concatenate(chunks)\n",
                "            segments, _ = self._whisper.transcribe(audio_data, beam_size=1, language=\"en\")\n",
                "            text = \" \".join(s.text for s in segments).strip()\n",
                "            \n",
                "            if text:\n",
                "                yield stt.SpeechEvent(\n",
                "                    type=stt.SpeechEventType.FINAL_TRANSCRIPT,\n",
                "                    alternatives=[stt.SpeechData(text=text)],\n",
                "                )\n",
                "            yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "        return _transcribe()\n",
                "\n",
                "    async def tts_node(\n",
                "        self, text: AsyncIterable[str], model_settings: ModelSettings\n",
                "    ) -> AsyncIterable[rtc.AudioFrame]:\n",
                "        buffer = \"\"\n",
                "        sr, spf = 32000, 640  # 20ms frames\n",
                "\n",
                "        def to_frames(pcm: np.ndarray):\n",
                "            pcm = np.clip(pcm, -1.0, 1.0)\n",
                "            pcm_i16 = (pcm * 32767).astype(np.int16)\n",
                "            for i in range(0, len(pcm_i16), spf):\n",
                "                chunk = pcm_i16[i:i+spf]\n",
                "                if len(chunk) < spf:\n",
                "                    chunk = np.pad(chunk, (0, spf - len(chunk)))\n",
                "                yield rtc.AudioFrame(data=chunk.tobytes(), sample_rate=sr, num_channels=1, samples_per_channel=spf)\n",
                "\n",
                "        async def speak(sentence: str):\n",
                "            for chunk in self._soprano.infer_stream(sentence, chunk_size=1):\n",
                "                pcm = np.asarray(chunk, dtype=np.float32)\n",
                "                for frame in to_frames(pcm):\n",
                "                    yield frame\n",
                "\n",
                "        async for delta in text:\n",
                "            buffer += delta\n",
                "            while (m := self._sent_re.match(buffer)):\n",
                "                sentence = m.group(1)\n",
                "                buffer = buffer[len(sentence):]\n",
                "                async for frame in speak(sentence):\n",
                "                    yield frame\n",
                "        if buffer.strip():\n",
                "            async for frame in speak(buffer):\n",
                "                yield frame\n",
                "\n",
                "\n",
                "def prewarm(proc: agents.JobProcess):\n",
                "    print(\"Loading VAD...\")\n",
                "    proc.userdata[\"vad\"] = silero.VAD.load(\n",
                "        min_speech_duration=0.05, min_silence_duration=0.35, force_cpu=True\n",
                "    )\n",
                "    print(\"Loading Whisper...\")\n",
                "    proc.userdata[\"whisper\"] = WhisperModel(\"tiny\", device=\"cuda\", compute_type=\"float16\")\n",
                "    print(\"Loading Soprano...\")\n",
                "    proc.userdata[\"soprano\"] = SopranoTTS(device=\"cuda\")\n",
                "    print(\"âœ… All models loaded\")\n",
                "\n",
                "\n",
                "async def entrypoint(ctx: agents.JobContext):\n",
                "    instructions = os.getenv(\"SYSTEM_PROMPT\", \"You are a helpful voice assistant. Be concise.\")\n",
                "    \n",
                "    agent = VoiceAgent(\n",
                "        whisper=ctx.proc.userdata[\"whisper\"],\n",
                "        soprano=ctx.proc.userdata[\"soprano\"],\n",
                "        instructions=instructions,  # Pass instructions here\n",
                "    )\n",
                "    \n",
                "    session = AgentSession(\n",
                "        turn_detection=\"vad\",\n",
                "        vad=ctx.proc.userdata[\"vad\"],\n",
                "        llm=google.realtime.RealtimeModel(\n",
                "            model=os.getenv(\"GEMINI_MODEL\", \"gemini-2.5-flash\"),\n",
                "            modalities=[Modality.TEXT],\n",
                "            instructions=instructions,\n",
                "            temperature=0.3,\n",
                "        ),\n",
                "        preemptive_generation=True,\n",
                "    )\n",
                "    await session.start(agent=agent, room=ctx.room)\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    cli.run_app(\n",
                "        WorkerOptions(\n",
                "            entrypoint_fnc=entrypoint,\n",
                "            prewarm_fnc=prewarm,\n",
                "            initialize_process_timeout=300.0,  # 5 min for model downloads\n",
                "            num_idle_processes=0,              # No parallel downloads\n",
                "            job_executor_type=JobExecutorType.THREAD,  # Better for Colab\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Run Agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python livekit_agent.py start"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ðŸ§ª Test Your Agent\n",
                "\n",
                "1. Go to [LiveKit Playground](https://agents-playground.livekit.io/)\n",
                "2. Enter your LiveKit URL and credentials\n",
                "3. Join a room and start talking!\n",
                "\n",
                "## ðŸ”§ Troubleshooting\n",
                "\n",
                "| Issue | Fix |\n",
                "|-------|-----|\n",
                "| Timeout errors | Run cell 3 first to pre-cache models |\n",
                "| CUDA OOM | Restart runtime, run cells in order |\n",
                "| Soprano backend error | `!pip install soprano-tts[transformers]` |"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}