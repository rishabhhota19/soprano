{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¤ LiveKit Voice Agent v4\n",
                "\n",
                "**Whisper STT â†’ Gemini Flash â†’ Soprano TTS**\n",
                "\n",
                "Pre-loads models to avoid subprocess timeouts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q \"livekit-agents[google,silero]~=1.3\" faster-whisper soprano-tts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === PRE-LOAD ALL MODELS (before LiveKit starts) ===\n",
                "import os\n",
                "os.environ[\"HF_HOME\"] = \"/content/hf_cache\"\n",
                "\n",
                "print(\"Loading Faster Whisper...\")\n",
                "from faster_whisper import WhisperModel\n",
                "WHISPER = WhisperModel(\"tiny\", device=\"cuda\", compute_type=\"float16\")\n",
                "print(\"âœ… Whisper\")\n",
                "\n",
                "print(\"Loading Soprano TTS...\")\n",
                "from soprano import SopranoTTS\n",
                "SOPRANO = SopranoTTS(device=\"cuda\")\n",
                "print(\"âœ… Soprano\")\n",
                "\n",
                "print(\"Loading Silero VAD...\")\n",
                "from livekit.plugins import silero\n",
                "VAD = silero.VAD.load(min_speech_duration=0.05, min_silence_duration=0.35, force_cpu=True)\n",
                "print(\"âœ… VAD\")\n",
                "\n",
                "print(\"\\nðŸŽ‰ All models pre-loaded! Run next cell.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "# ========== REPLACE WITH YOUR CREDENTIALS ==========\n",
                "os.environ[\"LIVEKIT_URL\"] = \"wss://YOUR-PROJECT.livekit.cloud\"\n",
                "os.environ[\"LIVEKIT_API_KEY\"] = \"YOUR_API_KEY\"\n",
                "os.environ[\"LIVEKIT_API_SECRET\"] = \"YOUR_API_SECRET\"\n",
                "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_GOOGLE_API_KEY\"\n",
                "# =====================================================\n",
                "\n",
                "print(\"âœ… Credentials set\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile livekit_agent_v4.py\n",
                "\"\"\"LiveKit Voice Agent v4: Whisper â†’ Gemini Flash â†’ Soprano\"\"\"\n",
                "\n",
                "import os\n",
                "import re\n",
                "import numpy as np\n",
                "from typing import AsyncIterable, Optional\n",
                "\n",
                "from livekit import agents, rtc\n",
                "from livekit.agents import Agent, AgentSession, ModelSettings, stt, cli\n",
                "from livekit.agents.worker import WorkerOptions\n",
                "from livekit.agents.job import JobExecutorType\n",
                "from livekit.plugins import google, silero\n",
                "\n",
                "# Import pre-loaded globals from notebook\n",
                "from faster_whisper import WhisperModel\n",
                "from soprano import SopranoTTS\n",
                "\n",
                "\n",
                "class VoiceAgent(Agent):\n",
                "    def __init__(self, whisper, soprano, instructions: str):\n",
                "        super().__init__(instructions=instructions)\n",
                "        self._whisper = whisper\n",
                "        self._soprano = soprano\n",
                "        self._sent_re = re.compile(r\"(.+?[.!?]\\s+|.+?\\n+)\", re.DOTALL)\n",
                "\n",
                "    async def stt_node(self, audio: AsyncIterable[rtc.AudioFrame], model_settings: ModelSettings):\n",
                "        \"\"\"Custom STT using Faster Whisper\"\"\"\n",
                "        async def _transcribe():\n",
                "            chunks = []\n",
                "            async for frame in audio:\n",
                "                samples = np.frombuffer(frame.data, dtype=np.int16).astype(np.float32) / 32768.0\n",
                "                chunks.append(samples)\n",
                "            if not chunks:\n",
                "                yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "                return\n",
                "            audio_data = np.concatenate(chunks)\n",
                "            segments, _ = self._whisper.transcribe(audio_data, beam_size=1, language=\"en\")\n",
                "            text = \" \".join(s.text for s in segments).strip()\n",
                "            print(f\"ðŸŽ¤ User: {text}\")\n",
                "            if text:\n",
                "                yield stt.SpeechEvent(\n",
                "                    type=stt.SpeechEventType.FINAL_TRANSCRIPT,\n",
                "                    alternatives=[stt.SpeechData(text=text)],\n",
                "                )\n",
                "            yield stt.SpeechEvent(type=stt.SpeechEventType.END_OF_SPEECH, alternatives=[])\n",
                "        return _transcribe()\n",
                "\n",
                "    async def tts_node(self, text: AsyncIterable[str], model_settings: ModelSettings):\n",
                "        \"\"\"Custom TTS using Soprano infer_stream\"\"\"\n",
                "        buffer = \"\"\n",
                "        sr, spf = 32000, 640  # 20ms frames at 32kHz\n",
                "\n",
                "        def to_frames(pcm: np.ndarray):\n",
                "            pcm = np.clip(pcm, -1.0, 1.0)\n",
                "            pcm_i16 = (pcm * 32767).astype(np.int16)\n",
                "            for i in range(0, len(pcm_i16), spf):\n",
                "                chunk = pcm_i16[i:i+spf]\n",
                "                if len(chunk) < spf:\n",
                "                    chunk = np.pad(chunk, (0, spf - len(chunk)))\n",
                "                yield rtc.AudioFrame(\n",
                "                    data=chunk.tobytes(),\n",
                "                    sample_rate=sr,\n",
                "                    num_channels=1,\n",
                "                    samples_per_channel=spf\n",
                "                )\n",
                "\n",
                "        async def speak(sentence: str):\n",
                "            print(f\"ðŸ”Š Agent: {sentence.strip()}\")\n",
                "            for chunk in self._soprano.infer_stream(sentence, chunk_size=1):\n",
                "                pcm = np.asarray(chunk, dtype=np.float32)\n",
                "                for frame in to_frames(pcm):\n",
                "                    yield frame\n",
                "\n",
                "        async for delta in text:\n",
                "            buffer += delta\n",
                "            while (m := self._sent_re.match(buffer)):\n",
                "                sentence = m.group(1)\n",
                "                buffer = buffer[len(sentence):]\n",
                "                async for frame in speak(sentence):\n",
                "                    yield frame\n",
                "        if buffer.strip():\n",
                "            async for frame in speak(buffer):\n",
                "                yield frame\n",
                "\n",
                "\n",
                "def prewarm(proc: agents.JobProcess):\n",
                "    \"\"\"Load models - uses pre-loaded globals to avoid timeout\"\"\"\n",
                "    print(\"Loading models...\")\n",
                "    # Re-load here since subprocess doesn't share memory with notebook\n",
                "    proc.userdata[\"whisper\"] = WhisperModel(\"tiny\", device=\"cuda\", compute_type=\"float16\")\n",
                "    proc.userdata[\"soprano\"] = SopranoTTS(device=\"cuda\")\n",
                "    proc.userdata[\"vad\"] = silero.VAD.load(\n",
                "        min_speech_duration=0.05, min_silence_duration=0.35, force_cpu=True\n",
                "    )\n",
                "    print(\"âœ… Models loaded\")\n",
                "\n",
                "\n",
                "async def entrypoint(ctx: agents.JobContext):\n",
                "    instructions = \"You are a helpful voice assistant. Keep responses concise, 1-2 sentences.\"\n",
                "    \n",
                "    agent = VoiceAgent(\n",
                "        whisper=ctx.proc.userdata[\"whisper\"],\n",
                "        soprano=ctx.proc.userdata[\"soprano\"],\n",
                "        instructions=instructions,\n",
                "    )\n",
                "    \n",
                "    session = AgentSession(\n",
                "        turn_detection=\"vad\",\n",
                "        vad=ctx.proc.userdata[\"vad\"],\n",
                "        llm=google.LLM(model=\"gemini-2.0-flash\"),  # Text-to-text API\n",
                "    )\n",
                "    \n",
                "    await session.start(agent=agent, room=ctx.room)\n",
                "    print(\"ðŸŽ¤ Listening...\")\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    cli.run_app(\n",
                "        WorkerOptions(\n",
                "            entrypoint_fnc=entrypoint,\n",
                "            prewarm_fnc=prewarm,\n",
                "            initialize_process_timeout=120.0,  # 2 min for model loading\n",
                "            num_idle_processes=0,  # Single process, no parallel loading\n",
                "            job_executor_type=JobExecutorType.THREAD,  # Better for Colab\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python livekit_agent_v4.py start"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ðŸ§ª Test\n",
                "\n",
                "1. Go to [LiveKit Playground](https://agents-playground.livekit.io/)\n",
                "2. Enter your LiveKit credentials\n",
                "3. Join a room and speak!\n",
                "\n",
                "## ðŸ”§ Troubleshooting\n",
                "\n",
                "| Issue | Fix |\n",
                "|-------|-----|\n",
                "| Still timing out | Increase `initialize_process_timeout` to 300.0 |\n",
                "| Model not found | Make sure cell 3 ran successfully |\n",
                "| Gemini error | Check your `GOOGLE_API_KEY` is valid |"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}